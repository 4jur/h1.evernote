#!/usr/bin/env python3

import argparse
from base64 import b64decode
from typing import List, AnyStr
from bs4 import BeautifulSoup
import bs4
import csv
import os
import requests

from http.server import BaseHTTPRequestHandler
from io import BytesIO

class HTTPRequest(BaseHTTPRequestHandler):
    def __init__(self, request_text):
        self.rfile = BytesIO(request_text)
        self.raw_requestline = self.rfile.readline()
        self.error_code = self.error_message = None
        self.parse_request()
#        print(dir(self))

    def send_error(self, code, message):
        self.error_code = code
        self.error_message = message


def main():
    parser = argparse.ArgumentParser(description='A script to parse Burp Suite XML base64 encoded files to CSV')
    parser.add_argument('-f', '--filename', help='XML file to parse', required=True)
    parser.add_argument('-o', '--outfile', help='Filename of the parsed XML to save as a CSV file', required=True)

    args = parser.parse_args()

    xml_file_to_parse: AnyStr = args.filename
    save_location: AnyStr = args.outfile
    dir_path: AnyStr = os.path.dirname(os.path.realpath(__file__)) + '/'
    file_path: AnyStr = dir_path + xml_file_to_parse
    with open(file_path, 'r') as f:
        data_in = f.read()
    soup = bs4.BeautifulSoup(markup=data_in, features="xml")

    items = soup.find("items")
    print(len(items))
    itemcount = 0
    childcount = 0
    for item in items:
        if isinstance(item, bs4.element.NavigableString):
            continue
        print("Item.name:", item.name)
        itemcount += 1
        if itemcount >=4:
            break
        childs = item.findChildren()
        for child in childs:
            childcount += 1
            if child.name in ['method', 'url', 'path', 'status']:
                #print("   ", "Child:", child.name, child.string)
                pass
            elif child.name in ['request', 'response']:
                print("   ", "Child:", child.name, len(child.string))
                print(b64decode(child.string)[:1000])
                print('-------------------------------------')

                html = b64decode(child.string)
#                req = bs4.BeautifulSoup(markup=html, features='html')

                if child.name == 'request':
                    req = HTTPRequest(html)
    #                print(html)                
    #                print(req.error_code)
                    if req.error_code is not None:
                        print(" -- parsing error--")
                        print(req.error_message)
                        continue
#                print(req.headers)
#                print(type(req.headers))
                
                
#                print(req.command)
#                print(dir(req))
#                parsed = req.parse_request()
#                print(dir(parsed))
                
#                cookies = req.find('Cookies')
#                print(len(cookies), cookies)
#                print(dir(req))

#                gchilds = req.findChildren()
#                print("GCHILDCOUNT:", len(gchilds))
#                for gchild in gchilds:
#                    print(gchild.name)
#                print('-------------------------------------')
                
#                print(page)
#            else:
#                print("   ", "Child:", child.name)

    print("itemcount:", itemcount, "  childcount:", childcount)
    '''
    for entries in issues:
        vuln_name = entries.find('name').text.replace('<![CDATA[', '').replace(']]>', '')
        host = entries.find('host')
        ip = host['ip']
        host = host.text
        location = entries.find('location').text.replace('<![CDATA[', '').replace(']]>', '')
        severity = entries.find('severity').text
        confidence = entries.find('confidence').text

        issue_background = entries.find('issuebackground').text.replace("<p>", "").replace("</p>", "").replace(
            '<![CDATA[', '').replace(']]>', '').replace('\n', '')
        remediation_background = entries.find('remediationbackground')
        vulnerability_classification = entries.find('vulnerabilityclassifications')
        data_request = entries.find('requestresponse').text
        request = b64decode(data_request.replace('<![CDATA[', '').replace(']]>', '')).decode()
        response = b64decode(
            entries.find('requestresponse').find('response').text.replace('<![CDATA[', '').replace(']]>', '')).decode()
        issue_detail = entries.find('issuedetail')

        results = (vuln_name, host, ip, location, severity, confidence, issue_background, remediation_background,
                   vulnerability_classification, issue_detail, request, response)
        issue_data.append(results)

        with open(save_location, 'w+') as outfile:
            if issue_data is not None:
                writer = csv.writer(outfile)
                writer.writerow(
                    ['Vulnerability', 'Host', 'IP', 'Location', 'Severity', 'Confidence', 'Issue Background',
                     'Remediation Background', 'Vulnerability Classification', 'Issue Details', 'request', 'response'])
                writer.writerows(issue_data)
    '''

if __name__ == '__main__':
    main()
